{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#初始设定：\n",
    "dataID='660b3ac5000000001a0110a8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>⃒⃘⃤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>- 绝了真绝了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>！ 这个AI说中文跟我老板有点像[汗颜R][汗颜R]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>！！</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      content\n",
       "0                         ⃒⃘⃤\n",
       "1                     - 绝了真绝了\n",
       "2  ！ 这个AI说中文跟我老板有点像[汗颜R][汗颜R]\n",
       "3                          !!\n",
       "4                          ！！"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataCleaned=pd.read_excel('data/xhs/'+dataID+'/output-660b3ac5000000001a0110a8.xlsx',sheet_name='RmAT')\n",
    "DataCleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\18054\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.502 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "切词后：  22712 ⃒ ⃘ ⃤\n"
     ]
    }
   ],
   "source": [
    "#添加新的关键词\n",
    "words = ['乙女游戏', 'chatgpt', 'gpt', 'Dan', 'dan模式','人机恋','小红书','饭圈','笑死','秀恩爱','偷笑R','智性恋','巴别塔','提示词','网爆','网暴','CNN','拉黑']\n",
    "\n",
    "xhs_emoji=['微笑R','害羞R','失望R','汗颜R','哇R','喝奶茶R','自拍R','偷笑R','飞吻R','石化R','笑哭R','赞R','蹲后续H','暗中观察R','买爆R','大笑R','色色R','生气R','哭惹R','萌萌哒R','斜眼R','可怜R','鄙视R','皱眉R','抓狂R','捂脸R','派对R','吧唧R','惊恐R','抠鼻R','再见R','叹气R','睡觉R','得意R','吃瓜R','扶墙R','黑薯问号R','黄金薯R','吐舌头H','扯脸H','doge','点赞R','向右R','合十R','okR','加油R','握手R','鼓掌R','弱R','耶R','抱拳R','勾引R','拳头R','拥抱R','举手R','红色心形R','黄色心形R','绿色心形R','蓝色心形R','紫色心形R','爱心R','两颗心R']\n",
    "\n",
    "#设置停用词\n",
    "with open('stopwords/cn_stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    cn_stopwords = [line.strip() for line in f]\n",
    "\n",
    "with open('stopwords/baidu_stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    baidu_stopwords = [line.strip() for line in f]\n",
    "\n",
    "with open('stopwords/hit_stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    hit_stopwords = [line.strip() for line in f]\n",
    "\n",
    "with open('stopwords/scu_stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    scu_stopwords = [line.strip() for line in f]\n",
    "\n",
    "for word in words:\n",
    "    jieba.add_word(word)\n",
    "\n",
    "for word in xhs_emoji:\n",
    "    jieba.add_word(word)\n",
    "\n",
    "cutted_text=[]\n",
    "word_list=[]\n",
    "for index, row in DataCleaned.iterrows():\n",
    "    text = row['content']\n",
    "    if(isinstance(text, str)): \n",
    "        result1=jieba.lcut(text)\n",
    "        filtered_words = [word for word in result1 if word not in cn_stopwords \n",
    "                          and word not in baidu_stopwords \n",
    "                          and word not in hit_stopwords \n",
    "                          and word not in scu_stopwords \n",
    "                          and word!=' ']\n",
    "    # print(filtered_words)\n",
    "    word_list.extend(filtered_words)\n",
    "    cutted_text.append(' '.join(filtered_words))\n",
    "\n",
    "print('切词后： ', len(cutted_text), cutted_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/xhs/'+dataID+'/cutword.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(cutted_text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIDating",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
